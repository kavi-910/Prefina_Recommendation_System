{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavi-910/Prefina_Recommendation_System/blob/main/ALS_Recommendation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nfche2IFapd0"
      },
      "outputs": [],
      "source": [
        "#Environment Setup\n",
        "\n",
        "#Installing packages\n",
        "!pip install --quiet \\\n",
        "  pandas numpy scikit-learn \\\n",
        "  lightfm implicit scipy \\\n",
        "  pyarrow tqdm ipywidgets\n",
        "\n",
        "#Installing visualization tools\n",
        "!pip install --quiet seaborn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXzhyxbzoiF5"
      },
      "outputs": [],
      "source": [
        "#Setting random seed\n",
        "import random, os, numpy as np\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIjeNH1SOprP"
      },
      "outputs": [],
      "source": [
        "#Import Libraries & Configurations\n",
        "\n",
        "#Core\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#ML & Recommender\n",
        "from lightfm import LightFM\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "\n",
        "#Utility\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import csr_matrix\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "#Display settings for clean output\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRACJWIto6Dq"
      },
      "outputs": [],
      "source": [
        "#Uploading datasets\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "df_products = pd.read_csv('products_H&M.csv')\n",
        "df_users = pd.read_csv('customers_H&M.csv')\n",
        "df_interactions = pd.read_csv('customer_interactions_H&M.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ5UK8r_GQmc"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Products Shape: \", df_products.shape)\n",
        "print(\"\\n Products Sample:\")\n",
        "display(df_products.head())\n",
        "\n",
        "print(\"\\n Users Shape: \", df_users.shape)\n",
        "print(\"\\n Users Sample:\")\n",
        "display(df_users.head())\n",
        "\n",
        "print(\"\\n Interactions Shape: \", df_interactions.shape)\n",
        "print(\"\\n Interactions Sample:\")\n",
        "display(df_interactions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHC5Vi_XOLqA"
      },
      "outputs": [],
      "source": [
        "#Data cleaning\n",
        "\n",
        "# 1 - Strip(clear) whitespace and lowercase columns\n",
        "df_products.columns = df_products.columns.str.strip().str.lower()\n",
        "df_users.columns = df_users.columns.str.strip().str.lower()\n",
        "df_interactions.columns = df_interactions.columns.str.strip().str.lower()\n",
        "\n",
        "# 2 - Remove duplicate rows\n",
        "df_products.drop_duplicates(inplace = True)\n",
        "df_users.drop_duplicates(inplace = True)\n",
        "df_interactions.drop_duplicates(inplace = True)\n",
        "\n",
        "# 3 - Drop missing values\n",
        "df_products.dropna(how='all', inplace = True)\n",
        "df_users.dropna(how='all', inplace = True)\n",
        "df_interactions.dropna(how='all', inplace = True)\n",
        "\n",
        "# 4 Resetting indexes\n",
        "df_products.reset_index(drop=True, inplace=True)\n",
        "df_users.reset_index(drop=True, inplace=True)\n",
        "df_interactions.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Products updated shape: \", df_products.shape)\n",
        "print(\"Users updated shape: \", df_users.shape)\n",
        "print(\"Interactions updated shape: \", df_interactions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkoI1qkdUb4t"
      },
      "outputs": [],
      "source": [
        "#Interaction Event Weighting\n",
        "\n",
        "# 1 - Standardize column names\n",
        "event_col = 'event_type' if 'event_type' in df_interactions.columns else 'event'\n",
        "\n",
        "# 2 - Define custom weighs for each event\n",
        "event_weights = {\n",
        "    'click': 2,\n",
        "    'wishlist': 2.5,\n",
        "    'add_to_cart': 3,\n",
        "    'rating': 4,\n",
        "    'purchase': 20\n",
        "}\n",
        "\n",
        "# 3 - Map event types to numerical weights\n",
        "df_interactions['event_weight'] = df_interactions[event_col].map(event_weights)\n",
        "\n",
        "# 4 - Display\n",
        "print(\"Events mapped: \")\n",
        "display(df_interactions[[event_col, 'event_weight']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziVj39F5ijz0"
      },
      "outputs": [],
      "source": [
        "#Aggregate user-product scores\n",
        "\n",
        "# 1 - Group by user_id and product_id\n",
        "df_user_product_scores = df_interactions.groupby(['user_id','product_id'])['event_weight'].sum().reset_index()\n",
        "\n",
        "# 2 - Sort by user-product scores\n",
        "df_user_product_scores.sort_values(by='event_weight', ascending=False, inplace=True)\n",
        "\n",
        "# 3 - Display\n",
        "print(\"Aggregated interaction scores: \")\n",
        "display(df_user_product_scores.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqPCi2xxlAp5"
      },
      "outputs": [],
      "source": [
        "# Encoding user_id and product_id\n",
        "\n",
        "# 1 - Create user and product encoders\n",
        "user_encoder = LabelEncoder()\n",
        "product_encoder = LabelEncoder()\n",
        "\n",
        "# 2 - Fit and transform the columns\n",
        "df_user_product_scores['user_idx'] = user_encoder.fit_transform(df_user_product_scores['user_id'])\n",
        "df_user_product_scores['product_idx'] = product_encoder.fit_transform(df_user_product_scores['product_id'])\n",
        "\n",
        "# 3 - Save encoded mappings\n",
        "user2idx = dict(zip(df_user_product_scores['user_id'], df_user_product_scores['user_idx']))\n",
        "idx2user = dict(zip(df_user_product_scores['user_idx'], df_user_product_scores['user_id']))\n",
        "#list(user2idx.items())[:10]\n",
        "\n",
        "product2idx = dict(zip(df_user_product_scores['product_id'], df_user_product_scores['product_idx']))\n",
        "idx2product = dict(zip(df_user_product_scores['product_idx'], df_user_product_scores['product_id']))\n",
        "\n",
        "# 4 - Display encoded mappings\n",
        "print(\"Encoded Mappings: \")\n",
        "display(df_user_product_scores.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5UP1Jk4o6Xx"
      },
      "outputs": [],
      "source": [
        "#Building sparse matrix\n",
        "\n",
        "# 1 - Prepare the daat needed for the matix\n",
        "user_indices = df_user_product_scores['user_idx'].values\n",
        "product_indices = df_user_product_scores['product_idx'].values\n",
        "weights_vec = df_user_product_scores['event_weight'].values\n",
        "\n",
        "# 2 - Build the sparse matrix\n",
        "\n",
        "#count how many unique users and products)\n",
        "num_users = df_user_product_scores['user_idx'].nunique()\n",
        "num_products = df_user_product_scores['product_idx'].nunique()\n",
        "\n",
        "#builds matrix\n",
        "interaction_matrix = csr_matrix((weights_vec, (user_indices, product_indices)), shape=(num_users, num_products))\n",
        "\n",
        "# 3 - Display matrix shape and density\n",
        "non_zero = interaction_matrix.count_nonzero()\n",
        "density = non_zero / (interaction_matrix.shape[0]*interaction_matrix.shape[1])\n",
        "\n",
        "print(\"Matrix shape: \", interaction_matrix.shape)\n",
        "print(\"Non-zero entries: \", non_zero)\n",
        "print(f\"Matrix density: {density:.4%}\")\n",
        "\n",
        "# Display matrix\n",
        "\n",
        "# Convert first 5 rows to dense format\n",
        "matrix_preview = interaction_matrix[:5].toarray()\n",
        "# Convert into readable df\n",
        "import pandas as pd\n",
        "matrix_df = pd.DataFrame(matrix_preview)\n",
        "display(matrix_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6ZJnn9fxw09"
      },
      "outputs": [],
      "source": [
        "# Matrix diagnostics & Sparsity Visualization\n",
        "# Diagnostics: User/Product Activity stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1 - Total interactions per user\n",
        "user_activity = interaction_matrix.sum(axis=1).A1\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.histplot(user_activity, bins=30, kde=False, color='pink')\n",
        "plt.title(\"Interactions per User\")\n",
        "plt.xlabel(\"Total Weighted Interactions\")\n",
        "plt.ylabel(\"Number of Users\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjOfRHln9iCN"
      },
      "outputs": [],
      "source": [
        "# 2 - Total interactions per product\n",
        "product_activity = interaction_matrix.sum(axis=0).A1\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.histplot(product_activity, bins=30, kde=False, color='purple')\n",
        "plt.title(\"Interactions per Product\")\n",
        "plt.xlabel(\"Total Weighted Interactions\")\n",
        "plt.ylabel(\"Number of Products\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2W0GtAE9j0l"
      },
      "outputs": [],
      "source": [
        "# Sparsity heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(interaction_matrix[:20, :20].toarray(), cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Heatmap of First 20x20 Users-Products\")\n",
        "plt.xlabel(\"Products\")\n",
        "plt.ylabel(\"Users\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aas5UGzKanCR"
      },
      "outputs": [],
      "source": [
        "# Train‚ÄìTest Split  (reproducible 80/20 leave-one-out)\n",
        "\n",
        "import random\n",
        "from scipy.sparse import csr_matrix, lil_matrix\n",
        "\n",
        "interaction_lil = interaction_matrix.tolil()          # full user√óitem\n",
        "test_matrix     = lil_matrix(interaction_matrix.shape)\n",
        "\n",
        "for u in range(interaction_matrix.shape[0]):\n",
        "    items = interaction_matrix[u].nonzero()[1]\n",
        "    if len(items) >= 2:\n",
        "        test_item = random.choice(items)              # hold-out ONE item\n",
        "        test_matrix[u, test_item]  = interaction_matrix[u, test_item]\n",
        "        interaction_lil[u, test_item] = 0             # remove from train\n",
        "\n",
        "train_matrix = interaction_lil.tocsr()\n",
        "test_matrix  = test_matrix.tocsr()\n",
        "\n",
        "print(\"Train:\", train_matrix.shape, \"| non-zeros:\", train_matrix.count_nonzero())\n",
        "print(\"Test :\",  test_matrix.shape,  \"| non-zeros:\", test_matrix.count_nonzero())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXeFMbDfaoxS"
      },
      "outputs": [],
      "source": [
        "# Build confidence matrices\n",
        "alpha = 40\n",
        "\n",
        "# user √ó item : 300 users √ó 1100 items  (keeps original orientation)\n",
        "conf_matrix = train_matrix * alpha\n",
        "\n",
        "# Fit model on the user-item confidence matrix directly\n",
        "item_user_conf = conf_matrix # Fit on user-item directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg5ZXdg7ip86"
      },
      "outputs": [],
      "source": [
        "# Precision@K helper\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def precision_at_k(model, conf_matrix, test_matrix, item_user_conf, K=10):\n",
        "    \"\"\"Mean Precision@K over users with at least one held-out item.\"\"\"\n",
        "    precisions = []\n",
        "    for u in range(test_matrix.shape[0]):\n",
        "        test_items = test_matrix[u].indices\n",
        "        if len(test_items) == 0:\n",
        "            continue\n",
        "\n",
        "        # extract a 1√óitems slice for this user\n",
        "        user_items = item_user_conf[:, u].T.tocsr()\n",
        "        # now user_items.shape == (1, num_items)\n",
        "\n",
        "        recs = model.recommend(\n",
        "            userid=u,\n",
        "            user_items=user_items,            # 1√ónum_items CSR\n",
        "            N=K,\n",
        "            filter_already_liked_items=True,\n",
        "            recalculate_user=True\n",
        "        )\n",
        "        recommended = recs[0] if isinstance(recs, tuple) else [iid for iid, _ in recs]\n",
        "        hits = len(np.intersect1d(test_items, recommended))\n",
        "        precisions.append(hits / K)\n",
        "\n",
        "    return np.mean(precisions) if precisions else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haC8X1P3licM"
      },
      "outputs": [],
      "source": [
        "from implicit.als import AlternatingLeastSquares\n",
        "\n",
        "# Create & train the model\n",
        "als = AlternatingLeastSquares(\n",
        "    factors=50,\n",
        "    regularization=0.05,\n",
        "    iterations=30,\n",
        "    random_state=42\n",
        ")\n",
        "als.fit(item_user_conf)    # item_user_conf is your CSR item√óuser matrix\n",
        "\n",
        "# Now you can call precision_at_k on `als`\n",
        "p10 = precision_at_k(als, conf_matrix, test_matrix, item_user_conf, K=10)\n",
        "print(\"Precision@10:\", p10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMAbWGlxl1gr"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Hyper-parameter grid search ‚îÄ‚îÄ\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "\n",
        "param_grid = {\n",
        "    \"factors\":        [20, 50, 100, 150],\n",
        "    \"regularization\": [0.005, 0.01, 0.05, 0.1],\n",
        "    \"iterations\":     [15, 30],\n",
        "}\n",
        "\n",
        "results = []\n",
        "for f, reg, iters in tqdm(list(product(*param_grid.values()))):\n",
        "    m = AlternatingLeastSquares(\n",
        "        factors        = f,\n",
        "        regularization = reg,\n",
        "        iterations     = iters,\n",
        "        random_state   = 42\n",
        "    )\n",
        "    m.fit(item_user_conf)\n",
        "    p10 = precision_at_k(m, conf_matrix, test_matrix, item_user_conf, K=10)\n",
        "    results.append({\n",
        "        \"factors\": f,\n",
        "        \"regularization\": reg,\n",
        "        \"iterations\": iters,\n",
        "        \"precision@10\": round(p10, 4)\n",
        "    })\n",
        "\n",
        "grid_results = pd.DataFrame(results).sort_values(\"precision@10\", ascending=False)\n",
        "display(grid_results.head(10))\n",
        "\n",
        "best = grid_results.iloc[0]\n",
        "print(\"\\nüîù Best params:\", dict(best))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpqMjMLUA6GG"
      },
      "outputs": [],
      "source": [
        "from implicit.als import AlternatingLeastSquares\n",
        "\n",
        "# 1Ô∏è‚É£ Create & train the model (naming it `als`)\n",
        "als = AlternatingLeastSquares(\n",
        "    factors=50,\n",
        "    regularization=0.1,\n",
        "    iterations=15,\n",
        ")\n",
        "als.fit(item_user_conf)    # item_user_conf is your CSR item√óuser matrix\n",
        "\n",
        "# 2Ô∏è‚É£ Now you can call precision_at_k on `als`\n",
        "p10 = precision_at_k(als, conf_matrix, test_matrix, item_user_conf, K=10)\n",
        "print(\"Precision@10:\", p10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzBr95XhdZiI"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Evaluation @K using column-vector approach ‚îÄ‚îÄ\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "def _recommend_ids(model, item_user_mat, user_id, K):\n",
        "    \"\"\"Return only item IDs from model.recommend (API-agnostic).\"\"\"\n",
        "    user_row = item_user_mat[:, user_id].T.tocsr()  # shape (1, num_items)\n",
        "    recs = model.recommend(\n",
        "        userid=user_id,\n",
        "        user_items=user_row,\n",
        "        N=K,\n",
        "        filter_already_liked_items=True,\n",
        "        recalculate_user=True,\n",
        "    )\n",
        "    return recs[0] if isinstance(recs, tuple) else [i for i, _ in recs]\n",
        "\n",
        "def ranking_metrics(model, item_user_mat, test_mat, K=10):\n",
        "    sums = defaultdict(float)\n",
        "    users_evaluated = 0\n",
        "\n",
        "    for u in tqdm(range(test_mat.shape[0]), desc=f\"Eval@{K}\"):\n",
        "        test_items = test_mat[u].indices\n",
        "        if test_items.size == 0:\n",
        "            continue\n",
        "        users_evaluated += 1\n",
        "\n",
        "        rec_items = _recommend_ids(model, item_user_mat, u, K)\n",
        "        rec_set, test_set = set(rec_items), set(test_items)\n",
        "\n",
        "        hits   = len(rec_set & test_set)\n",
        "        prec   = hits / K\n",
        "        recall = hits / len(test_set)\n",
        "\n",
        "        sums[\"P\"]   += prec\n",
        "        sums[\"R\"]   += recall\n",
        "        sums[\"HR\"]  += 1 if hits else 0\n",
        "\n",
        "        # AP for MAP\n",
        "        ap, num_hits = 0.0, 0\n",
        "        for rank, item in enumerate(rec_items, 1):\n",
        "            if item in test_set:\n",
        "                num_hits += 1\n",
        "                ap += num_hits / rank\n",
        "        ap /= len(test_set)\n",
        "        sums[\"AP\"] += ap\n",
        "\n",
        "        # DCG / IDCG for NDCG\n",
        "        dcg  = sum(\n",
        "            1 / np.log2(rank + 1)\n",
        "            for rank, item in enumerate(rec_items, 1)\n",
        "            if item in test_set\n",
        "        )\n",
        "        idcg = sum(\n",
        "            1 / np.log2(rank + 1)\n",
        "            for rank in range(1, min(len(test_set), K) + 1)\n",
        "        )\n",
        "        sums[\"DCG\"]  += dcg\n",
        "        sums[\"IDCG\"] += idcg\n",
        "\n",
        "    if users_evaluated == 0:\n",
        "        return {}\n",
        "\n",
        "    P    = sums[\"P\"]  / users_evaluated\n",
        "    R    = sums[\"R\"]  / users_evaluated\n",
        "    F1   = 2 * P * R / (P + R + 1e-8)\n",
        "    HR   = sums[\"HR\"] / users_evaluated\n",
        "    MAP  = sums[\"AP\"] / users_evaluated\n",
        "    NDCG = sums[\"DCG\"] / sums[\"IDCG\"] if sums[\"IDCG\"] else 0.0\n",
        "\n",
        "    return dict(Precision=P, Recall=R, F1=F1, HitRate=HR, MAP=MAP, NDCG=NDCG)\n",
        "\n",
        "# ‚îÄ‚îÄ Run evaluation ‚îÄ‚îÄ\n",
        "metrics = ranking_metrics(als, item_user_conf, test_matrix, K=10)\n",
        "\n",
        "print(\"\\n Evaluation @10 \")\n",
        "for name, val in metrics.items():\n",
        "    print(f\"{name:<9}: {val*100:6.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpIxiaPXei5j"
      },
      "outputs": [],
      "source": [
        "# # Heat-map\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "\n",
        "# # item_factors: (num_items √ó factors) matrix from ALS\n",
        "# item_factors = als.item_factors\n",
        "\n",
        "# # pairwise Pearson correlation between items\n",
        "# corr = np.corrcoef(item_factors)\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# sns.heatmap(\n",
        "#     corr,\n",
        "#     cmap=\"coolwarm\",\n",
        "#     square=True,\n",
        "#     annot=True,\n",
        "#     fmt=\".2f\",\n",
        "#     xticklabels=[idx2product[i] for i in range(len(corr))],\n",
        "#     yticklabels=[idx2product[i] for i in range(len(corr))]\n",
        "# )\n",
        "# plt.title(\"Item-factor correlation (ALS)\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdnBHhKQTIT2"
      },
      "outputs": [],
      "source": [
        "# tag mapping for meta data\n",
        "TAG_COLUMNS = [\"product_type\", \"color\", \"material\", \"pattern\", \"season\", \"price_range\"]\n",
        "\n",
        "product_to_tags = {}\n",
        "for _, row in df_products.iterrows():\n",
        "    pid = row[\"product_id\"]\n",
        "    tag_set = set()\n",
        "    for col in TAG_COLUMNS:\n",
        "        tag_val = str(row[col]).strip().lower()\n",
        "        tag_set.add(f\"{col}_{tag_val}\")\n",
        "    product_to_tags[pid] = tag_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huYtYBJiqgPK"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def tags_from_products(product_ids):\n",
        "    all_tags = []\n",
        "    for pid in product_ids:\n",
        "        all_tags.extend(product_to_tags.get(pid, []))\n",
        "    return Counter(all_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKC2QF_LnlBt"
      },
      "outputs": [],
      "source": [
        "# Tag recommendation\n",
        "\n",
        "def recommend_products_numeric(user_idx, k=5):\n",
        "    # ALS top-k product IDs given an integer user index\n",
        "    rec_ids, _ = als.recommend(\n",
        "        userid=int(user_idx),\n",
        "        user_items=train_matrix[int(user_idx)],\n",
        "        N=k,\n",
        "        filter_already_liked_items=True,\n",
        "        recalculate_user=True\n",
        "    )\n",
        "    return [idx2product[i] for i in rec_ids]\n",
        "\n",
        "def recommend_tags_numeric(user_idx, k_products=5, k_tags=5):\n",
        "    # Top tags after aggregating from top products\n",
        "    prods = recommend_products_numeric(user_idx, k=k_products)\n",
        "    tag_counts = tags_from_products(prods)       # Counter of tags\n",
        "    return tag_counts.most_common(k_tags)\n",
        "\n",
        "while True:\n",
        "    inp = input(\"\\nEnter numeric user ID (or 'quit'): \").strip()\n",
        "    if inp.lower() in {\"quit\", \"exit\"}:\n",
        "        break\n",
        "    if not inp.isdigit() or int(inp) >= train_matrix.shape[0]:\n",
        "        print(\" Please enter a valid numeric user index (0 ‚Äì\", train_matrix.shape[0]-1, \")\")\n",
        "        continue\n",
        "\n",
        "    uid = int(inp)\n",
        "    print(f\"\\n Recommendations for user {uid}\")\n",
        "\n",
        "    print(\" Products:\")\n",
        "    for pid in recommend_products_numeric(uid, k=5):\n",
        "        print(\"  ‚Ä¢\", pid)\n",
        "\n",
        "    print(\" Tags:\")\n",
        "    for tag, cnt in recommend_tags_numeric(uid, k_products=5, k_tags=5):\n",
        "        print(f\"  ‚Ä¢ {tag}  (score: {cnt})\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}